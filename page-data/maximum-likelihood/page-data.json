{"componentChunkName":"component---src-templates-post-js","path":"/maximum-likelihood/","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Maximum Likelihood","date":"2021-04-16T14:24:46.023Z","keyword":["machine-learning","statistic","mle"],"description":"A parameters estimation in stastical models."},"html":"<h1 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"link-class before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h1>\n<p>Supposed we have a dataset <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi><mrow><mi mathvariant=\"bold-italic\">D</mi><mo>=</mo><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mn mathvariant=\"bold\">1</mn></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mn mathvariant=\"bold\">2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">.</mi><mi mathvariant=\"bold\">.</mi><mi mathvariant=\"bold\">.</mi><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">x</mi><mi mathvariant=\"bold-italic\">n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mi></mrow><annotation encoding=\"application/x-tex\">\\bm{D = (x_1, x_2, ..., x_n)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.03194em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel mathbf\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mopen mathbf\">(</span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathbf mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathbf\">.</span><span class=\"mord mathbf\">.</span><span class=\"mord mathbf\">.</span><span class=\"mpunct mathbf\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord boldsymbol\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.161108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord boldsymbol mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose mathbf\">)</span></span></span></span></span></span> of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold-italic\">N</mi></mrow><annotation encoding=\"application/x-tex\">\\bm{N}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.11424em;\">N</span></span></span></span></span></span> independent observation.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span>\n<h1 id=\"maximum-likelihood-estimation\" style=\"position:relative;\"><a href=\"#maximum-likelihood-estimation\" aria-label=\"maximum likelihood estimation permalink\" class=\"link-class before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Maximum Likelihood Estimation</h1>","fields":{"slug":"/maximum-likelihood/"},"tableOfContents":"<ul>\n<li><a href=\"/maximum-likelihood/#introduction\">Introduction</a></li>\n<li><a href=\"/maximum-likelihood/#maximum-likelihood-estimation\">Maximum Likelihood Estimation</a></li>\n</ul>"}},"pageContext":{"previous":null,"next":{"fields":{"slug":"/logistic-regression/index-1/"},"frontmatter":{"title":"Logistic Regression"}},"series":{"slug":"machine-learning","description":"My basic knowledge of Machine Learning","posts":[{"frontmatter":{"title":"Maximum Likelihood","date":"2021-04-16T14:24:46.023Z","description":"A parameters estimation in stastical models.","keyword":["machine-learning","statistic","mle"],"series":"Machine Learning"},"fields":{"slug":"/maximum-likelihood/","readingTime":{"text":"1 min read"}}},{"frontmatter":{"title":"Logistic Regression","date":"2021-03-07T04:49:28.520Z","description":"A statiscal method for clasification task.","keyword":["supervised-learning","clasification","machine-learning"],"series":"Machine Learning"},"fields":{"slug":"/logistic-regression/index-1/","readingTime":{"text":"1 min read"}}},{"frontmatter":{"title":"K-nearest neighbors","date":"2021-03-07T04:45:35.148Z","description":"The most simple supervised learning algorithm.","keyword":["supervised-learning","machine-learning"],"series":"Machine Learning"},"fields":{"slug":"/k-nearest-neighbors/","readingTime":{"text":"1 min read"}}},{"frontmatter":{"title":"K-means Clustering","date":"2021-02-09T11:53:48.770Z","description":"One of the most well-known unsupervised learning algorithm.","keyword":["machine-learning","kmeans","unsupervised-learning"],"series":"Machine Learning"},"fields":{"slug":"/2-k-means-clustering/","readingTime":{"text":"1 min read"}}},{"frontmatter":{"title":"Gradient Descent","date":"2021-02-08T16:40:08.581Z","description":"The most common algorithm to perform optimization.","keyword":["machine-learning","gradient-descent","optimization"],"series":"Machine Learning"},"fields":{"slug":"/gradient-descent/","readingTime":{"text":"4 min read"}}},{"frontmatter":{"title":"Linear Regression","date":"2021-02-03T06:55:13.201Z","description":"In the first blog post of this series, we will discuss some basic concepts of Machine Learning and go into the first Machine Learning algorithm: Linear Regression.","keyword":["machine-learning","linear-regression","supervised-learning"],"series":"Machine Learning"},"fields":{"slug":"/1-linear-regression/","readingTime":{"text":"3 min read"}}}],"name":"Machine Learning"}}},"staticQueryHashes":["63159454"]}